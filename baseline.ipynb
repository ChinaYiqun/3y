{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "baseline",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOSL3WEM6UYL0esGTc3cE4/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChinaYiqun/3y/blob/master/baseline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbKEJ3IHJqBX"
      },
      "source": [
        "# 安装库"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7SsbZBEb3TVc"
      },
      "source": [
        "!pip install efficientnet\r\n",
        "import tensorflow.compat.v1 as tf\r\n",
        "tf.disable_v2_behavior()\r\n",
        "!wget https://www.robots.ox.ac.uk/~vgg/data/flowers/102/102flowers.tgz\r\n",
        "!wget https://www.robots.ox.ac.uk/~vgg/data/flowers/102/imagelabels.mat \r\n",
        "!tar zxvf 102flowers.tgz -C ./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF8iq07D4ODc"
      },
      "source": [
        "import os\r\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\r\n",
        "import numpy as np\r\n",
        "import shutil\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "import efficientnet.keras as efn \r\n",
        "conv_base = efn.EfficientNetB1(weights='imagenet',include_top=False,input_shape=(100, 100, 3))\r\n",
        "import efficientnet.keras as efn \r\n",
        "from keras.layers import Dense, Dropout, Flatten, AveragePooling2D\r\n",
        "from keras.models import Sequential, Model, load_model\r\n",
        "from scipy.io import loadmat\r\n",
        "data_m= loadmat(\"imagelabels.mat\")\r\n",
        "labels = data_m['labels'].tolist()[0]\r\n",
        "\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSrAAPnQBFR7"
      },
      "source": [
        "def mkdir_for_keras(dirname):\r\n",
        "  os.mkdir(dirname)\r\n",
        "  for i in range(1,103):\r\n",
        "    file_name=\"{}_label\".format(i)\r\n",
        "    os.makedirs(dirname + '/' + file_name)\r\n",
        "def move2dir(src,trainfolder,validfoder,labels,split = 0.2):\r\n",
        "  for folderName, subfolders, filenames in os.walk(src):\r\n",
        "    for filename in filenames:\r\n",
        "      if '.jpg' in filename:\r\n",
        "        file_id = int(filename.split('_')[1].split('.')[0]) -1\r\n",
        "        file_class = str(labels[file_id]) + '_label'\r\n",
        "        #print(np.random.random())\r\n",
        "      try:\r\n",
        "        p = np.random.random()\r\n",
        "        #print(p)\r\n",
        "        #print(folderName+ '/'+ filename,validfoder+ '/'+file_class +'/'+ filename)\r\n",
        "        \r\n",
        "        if p < split:\r\n",
        "          # 放入验证集\r\n",
        "          #print(folderName+ '/'+ filename,validfoder+ '/'+file_class +'/'+ filename)\r\n",
        "          shutil.move(folderName+ '/'+ filename,validfoder+ '/'+file_class +'/'+ filename)\r\n",
        "          \r\n",
        "          pass\r\n",
        "        else:\r\n",
        "          # 放入训练集\r\n",
        "          shutil.move(folderName+ '/'+ filename,trainfolder+ '/'+file_class +'/'+ filename)\r\n",
        "          pass\r\n",
        "        \r\n",
        "        pass \r\n",
        "      except:\r\n",
        "        print('io erro')\r\n",
        "        pass"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFx-Gfm35jT2"
      },
      "source": [
        "mkdir_for_keras('train')\r\n",
        "mkdir_for_keras('valid')\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FODKIGq1Axgt"
      },
      "source": [
        "move2dir('jpg','train','valid',labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hso9bheIJ4YH"
      },
      "source": [
        "# 构建模型"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnkHeEPu4pmc",
        "outputId": "e40bd4e0-2460-4864-a4a9-87acd6efbf3d"
      },
      "source": [
        "class constants():\r\n",
        "    def __init__(self):\r\n",
        "      pass\r\n",
        "# First time run, no unlocking\r\n",
        "conv_base.trainable = False\r\n",
        "\r\n",
        "# Let's construct that top layer replacement\r\n",
        "\r\n",
        "x = conv_base.output\r\n",
        "x = Flatten()(x)\r\n",
        "x = Dropout(0.25)(x)\r\n",
        "predictions = Dense(102,  kernel_initializer=\"glorot_uniform\", activation='softmax')(x)\r\n",
        "print('Stacking New Layers')\r\n",
        "model = Model(inputs = conv_base.input, outputs=predictions)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stacking New Layers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hmBf5X5W6oTu"
      },
      "source": [
        "\r\n",
        "\r\n",
        "        \r\n",
        "constants.NUM_CLASSES = 102\r\n",
        "constants.BASE_DIR = ('.')\r\n",
        "constants.SIZES = {\r\n",
        "    'basic': 100\r\n",
        "}\r\n",
        "height = constants.SIZES['basic']\r\n",
        "width = height\r\n",
        "constants.STEPS_PER_EPOCH = 400\r\n",
        "constants.TOTAL_EPOCHS = 10\r\n",
        "constants.GENERATOR_BATCH_SIZE = 20\r\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\r\n",
        "from time import time\r\n",
        "# Slow down training deeper into dataset\r\n",
        "def schedule(epoch):\r\n",
        "    if epoch < 6:\r\n",
        "        # Warmup model first\r\n",
        "        return .0000032\r\n",
        "    elif epoch < 12:\r\n",
        "        return .01\r\n",
        "    elif epoch < 20:\r\n",
        "        return .002\r\n",
        "    elif epoch < 30:\r\n",
        "        return .001\r\n",
        "    elif epoch < 40:\r\n",
        "        return .0004\r\n",
        "    elif epoch < 60:\r\n",
        "        return .00008\r\n",
        "    elif epoch < 80:\r\n",
        "        return .000016\r\n",
        "    elif epoch < 95:\r\n",
        "        return .0000032        \r\n",
        "    else:\r\n",
        "        return .0000009    \r\n",
        "def make_callbacks(weights_file):\r\n",
        "    # checkpoint\r\n",
        "    filepath = weights_file\r\n",
        "    checkpoint = ModelCheckpoint(\r\n",
        "        filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\r\n",
        "\r\n",
        "    # Update info\r\n",
        "    tensorboard = TensorBoard(log_dir=\"log/{}\".format(time()))\r\n",
        "\r\n",
        "    # learning rate schedule\r\n",
        "    lr_scheduler = LearningRateScheduler(schedule)\r\n",
        "\r\n",
        "    # all the goodies\r\n",
        "    return [lr_scheduler, checkpoint, tensorboard]\r\n",
        "## callbacks_list = make_callbacks(weights_file)\r\n",
        "import os\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "constants.BASE_DIR = ('.')\r\n",
        "# train_datagen = ImageDataGenerator(\r\n",
        "#     rescale=1./255,\r\n",
        "#     rotation_range=45,\r\n",
        "#     width_shift_range=0.2,\r\n",
        "#     height_shift_range=0.2,\r\n",
        "#     shear_range=0.2,\r\n",
        "#     zoom_range=0.2,\r\n",
        "#     channel_shift_range=20,\r\n",
        "#     horizontal_flip=True,\r\n",
        "#     fill_mode='nearest'\r\n",
        "# )\r\n",
        "\r\n",
        "train_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./255,\r\n",
        "    rotation_range=45,\r\n",
        "    horizontal_flip=True,\r\n",
        "    shear_range=0.5,\r\n",
        "    zoom_range=0.3,\r\n",
        "    fill_mode='wrap',\r\n",
        "    width_shift_range=0.2,\r\n",
        "    height_shift_range=0.2,\r\n",
        ")\r\n",
        "\r\n",
        "# Validation data should not be modified\r\n",
        "validation_datagen = ImageDataGenerator(\r\n",
        "    rescale=1./255\r\n",
        ")\r\n",
        "\r\n",
        "#train_dir = os.path.join(constants.BASE_DIR, 'data_train_clean')\r\n",
        "#test_dir = os.path.join(constants.BASE_DIR, 'data_test')\r\n",
        "train_dir = os.path.join(constants.BASE_DIR, 'train')\r\n",
        "# train_dir = os.path.join(constants.BASE_DIR, 'moredata')\r\n",
        "test_dir = os.path.join(constants.BASE_DIR, 'valid')\r\n",
        "def create_generators(height, width):\r\n",
        "    train_generator = train_datagen.flow_from_directory(\r\n",
        "        train_dir,\r\n",
        "        target_size=(height, width),\r\n",
        "        class_mode='categorical',\r\n",
        "        batch_size=constants.GENERATOR_BATCH_SIZE\r\n",
        "    )\r\n",
        "\r\n",
        "    validation_generator = validation_datagen.flow_from_directory(\r\n",
        "        test_dir,\r\n",
        "        target_size=(height, width),\r\n",
        "        class_mode='categorical',\r\n",
        "        batch_size=constants.GENERATOR_BATCH_SIZE\r\n",
        "    )\r\n",
        "\r\n",
        "    return[train_generator, validation_generator]\r\n",
        "  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oa8NcQ7H_a-L"
      },
      "source": [
        ""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_4h4GdG_T00",
        "outputId": "7e85290b-acc2-44f3-dd0c-544b13f7f13e"
      },
      "source": [
        "train_generator, validation_generator = create_generators(height, width)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6509 images belonging to 102 classes.\n",
            "Found 1680 images belonging to 102 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUytoXED_fbq"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, TensorBoard, LearningRateScheduler\r\n",
        "from time import time\r\n",
        "# Slow down training deeper into dataset\r\n",
        "def schedule(epoch):\r\n",
        "    if epoch < 5:\r\n",
        "        # Warmup model first\r\n",
        "        return .0000032\r\n",
        "    elif epoch < 12:\r\n",
        "        return .0000032 #0.1\r\n",
        "    elif epoch < 20:\r\n",
        "        return .002\r\n",
        "    elif epoch < 30:\r\n",
        "        return .001\r\n",
        "    elif epoch < 40:\r\n",
        "        return .0004\r\n",
        "    elif epoch < 60:\r\n",
        "        return .00008\r\n",
        "    elif epoch < 80:\r\n",
        "        return .000016\r\n",
        "    elif epoch < 95:\r\n",
        "        return .0000032        \r\n",
        "    else:\r\n",
        "        return .0000009 \r\n",
        "def make_callbacks(weights_file):\r\n",
        "    # checkpoint\r\n",
        "    filepath = weights_file\r\n",
        "    checkpoint = ModelCheckpoint(\r\n",
        "        filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\r\n",
        "\r\n",
        "    # Update info\r\n",
        "    tensorboard = TensorBoard(log_dir=\"log/{}\".format(time()))\r\n",
        "\r\n",
        "    # learning rate schedule\r\n",
        "    lr_scheduler = LearningRateScheduler(schedule)\r\n",
        "\r\n",
        "    # all the goodies\r\n",
        "    return [lr_scheduler, checkpoint, tensorboard]\r\n",
        "weights_file = 'checkpoint/best_weights.efficientnet-b4.hdf5'\r\n",
        "callbacks_list = make_callbacks(weights_file)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WS6Fyz05J71b"
      },
      "source": [
        "# 训练和评估"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrrDCNUH_lOz",
        "outputId": "f1889238-e9b8-4553-e30d-cbb27e9f97dd"
      },
      "source": [
        "from keras.optimizers import SGD,Adam\r\n",
        "print('Compile model')\r\n",
        "# originally adam, but research says SGD with scheduler\r\n",
        "opt = Adam(lr=0.01, amsgrad=True)\r\n",
        "#opt = SGD(momentum=1,lr=1,nesterov=True) #,clipnorm=1. clipnorm=0.8\r\n",
        "#opt = keras.optimizers.Adadelta( rho=0.95, epsilon=None, decay=0.0)\r\n",
        "#opt = keras.optimizers.Nadam(lr=0.1, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004)\r\n",
        "# lrate = 0.01 \r\n",
        "# epoch = 10\r\n",
        "# decay = lrate/epoch\r\n",
        "# opt = SGD(lr=0.01, momentum=0.9, nesterov=True)\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    loss='categorical_crossentropy',\r\n",
        "    optimizer=opt,\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "\r\n",
        "# Get training/validation data via generators\r\n",
        "train_generator, validation_generator = create_generators(height, width)\r\n",
        "print('Start training!')\r\n",
        "history = model.fit_generator(\r\n",
        "    train_generator,\r\n",
        "    callbacks=callbacks_list,\r\n",
        "    epochs=50,\r\n",
        "    steps_per_epoch=constants.STEPS_PER_EPOCH,\r\n",
        "    shuffle=True,\r\n",
        "    workers=4,\r\n",
        "    use_multiprocessing=True,\r\n",
        "    validation_data=validation_generator,\r\n",
        "    validation_steps=50\r\n",
        ")\r\n",
        "\r\n",
        "# Save it for later\r\n",
        "print('Saving Model')\r\n",
        "\r\n",
        "model.save(\"/content/drive/My Drive/Kaggle/40EfficientNetB3_size.\" + str(width) + \"x\" + str(height) + \".hdf5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "325/400 [=======================>......] - ETA: 11s - loss: 3.1952 - accuracy: 0.2682WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.1888 - accuracy: 0.2681WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 3.1887 - accuracy: 0.2681 - val_loss: 2.8099 - val_accuracy: 0.3590\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 11/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 3.0565 - accuracy: 0.2951WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.0566 - accuracy: 0.2945WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 3.0566 - accuracy: 0.2945 - val_loss: 2.7341 - val_accuracy: 0.3710\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 12/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 3.0295 - accuracy: 0.2850WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.0232 - accuracy: 0.2876WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 3.0231 - accuracy: 0.2876 - val_loss: 2.6183 - val_accuracy: 0.3980\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 13/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 7.2377 - accuracy: 0.2542WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 7.3291 - accuracy: 0.2669WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 7.3299 - accuracy: 0.2671 - val_loss: 6.6227 - val_accuracy: 0.5250\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 14/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 7.2421 - accuracy: 0.4622WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 7.2352 - accuracy: 0.4645WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 7.2349 - accuracy: 0.4645 - val_loss: 6.0204 - val_accuracy: 0.5750\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 15/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 6.1550 - accuracy: 0.5393WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 6.1709 - accuracy: 0.5398WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 70s 170ms/step - loss: 6.1709 - accuracy: 0.5398 - val_loss: 4.9954 - val_accuracy: 0.6530\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 16/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 5.7063 - accuracy: 0.5820WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "399/400 [============================>.] - ETA: 0s - loss: 5.7226 - accuracy: 0.5819WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 70s 171ms/step - loss: 5.7228 - accuracy: 0.5819 - val_loss: 4.7491 - val_accuracy: 0.6710\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 17/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 5.3499 - accuracy: 0.6089WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.3610 - accuracy: 0.6083WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 170ms/step - loss: 5.3610 - accuracy: 0.6083 - val_loss: 5.0728 - val_accuracy: 0.6780\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 18/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 5.2834 - accuracy: 0.6284WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.2741 - accuracy: 0.6287WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 170ms/step - loss: 5.2738 - accuracy: 0.6287 - val_loss: 5.4890 - val_accuracy: 0.6620\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 19/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 5.0234 - accuracy: 0.6424WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.0527 - accuracy: 0.6421WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 5.0528 - accuracy: 0.6421 - val_loss: 5.4402 - val_accuracy: 0.6960\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 20/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "324/400 [=======================>......] - ETA: 11s - loss: 4.7140 - accuracy: 0.6586WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.7359 - accuracy: 0.6586WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 170ms/step - loss: 4.7362 - accuracy: 0.6586 - val_loss: 5.2282 - val_accuracy: 0.6950\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 21/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 3.8959 - accuracy: 0.7141WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.8231 - accuracy: 0.7157WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 168ms/step - loss: 3.8221 - accuracy: 0.7157 - val_loss: 3.5529 - val_accuracy: 0.7450\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 22/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 3.2505 - accuracy: 0.7288WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.2385 - accuracy: 0.7293WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 3.2384 - accuracy: 0.7293 - val_loss: 3.4708 - val_accuracy: 0.7560\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 23/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 3.0300 - accuracy: 0.7314WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.0304 - accuracy: 0.7314WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 70s 171ms/step - loss: 3.0302 - accuracy: 0.7315 - val_loss: 3.7052 - val_accuracy: 0.7570\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 24/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 3.0942 - accuracy: 0.7337WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.0543 - accuracy: 0.7355WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 170ms/step - loss: 3.0537 - accuracy: 0.7356 - val_loss: 3.0650 - val_accuracy: 0.7540\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 25/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 2.7980 - accuracy: 0.7569WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.7830 - accuracy: 0.7567WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 170ms/step - loss: 2.7829 - accuracy: 0.7567 - val_loss: 3.4957 - val_accuracy: 0.7400\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 26/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 2.5553 - accuracy: 0.7659WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.5634 - accuracy: 0.7646WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 70s 171ms/step - loss: 2.5635 - accuracy: 0.7646 - val_loss: 3.4793 - val_accuracy: 0.7590\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 27/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 2.6683 - accuracy: 0.7542WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.6518 - accuracy: 0.7545WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 2.6516 - accuracy: 0.7545 - val_loss: 3.1490 - val_accuracy: 0.7740\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 28/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 2.4748 - accuracy: 0.7708WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.4636 - accuracy: 0.7708WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 68s 167ms/step - loss: 2.4634 - accuracy: 0.7708 - val_loss: 3.2339 - val_accuracy: 0.7790\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 29/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 2.4076 - accuracy: 0.7765WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.4103 - accuracy: 0.7749WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 168ms/step - loss: 2.4103 - accuracy: 0.7749 - val_loss: 2.9408 - val_accuracy: 0.7970\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 30/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 2.3731 - accuracy: 0.7744WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.3900 - accuracy: 0.7730WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 68s 168ms/step - loss: 2.3902 - accuracy: 0.7730 - val_loss: 2.8638 - val_accuracy: 0.7900\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 31/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 2.0582 - accuracy: 0.8014WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.0308 - accuracy: 0.8028WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 68s 167ms/step - loss: 2.0305 - accuracy: 0.8028 - val_loss: 2.6616 - val_accuracy: 0.7970\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 32/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "324/400 [=======================>......] - ETA: 11s - loss: 1.8098 - accuracy: 0.7997WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.8097 - accuracy: 0.8009WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 168ms/step - loss: 1.8096 - accuracy: 0.8010 - val_loss: 3.0442 - val_accuracy: 0.7920\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 33/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 1.8867 - accuracy: 0.8083WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.8782 - accuracy: 0.8079WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 70s 171ms/step - loss: 1.8782 - accuracy: 0.8079 - val_loss: 2.6516 - val_accuracy: 0.8090\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 34/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 1.7497 - accuracy: 0.8070WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.7468 - accuracy: 0.8071WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 1.7468 - accuracy: 0.8071 - val_loss: 2.6687 - val_accuracy: 0.8080\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 35/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 1.7141 - accuracy: 0.8042WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.7159 - accuracy: 0.8042WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 170ms/step - loss: 1.7160 - accuracy: 0.8042 - val_loss: 2.6131 - val_accuracy: 0.8040\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 36/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 1.7773 - accuracy: 0.8104WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.7645 - accuracy: 0.8109WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 1.7644 - accuracy: 0.8109 - val_loss: 2.4840 - val_accuracy: 0.8050\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 37/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 1.6740 - accuracy: 0.8116WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "399/400 [============================>.] - ETA: 0s - loss: 1.6697 - accuracy: 0.8119WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 169ms/step - loss: 1.6696 - accuracy: 0.8119 - val_loss: 2.5460 - val_accuracy: 0.7970\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 38/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "325/400 [=======================>......] - ETA: 11s - loss: 1.4965 - accuracy: 0.8321WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.5108 - accuracy: 0.8302WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 70s 171ms/step - loss: 1.5109 - accuracy: 0.8302 - val_loss: 2.4140 - val_accuracy: 0.8040\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 39/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 1.6209 - accuracy: 0.8196WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.6137 - accuracy: 0.8186WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "400/400 [==============================] - 69s 170ms/step - loss: 1.6136 - accuracy: 0.8185 - val_loss: 2.4186 - val_accuracy: 0.8070\n",
            "WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
            "Epoch 40/50\n",
            "WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "326/400 [=======================>......] - ETA: 11s - loss: 1.5868 - accuracy: 0.8215WARNING:tensorflow:multiprocessing can interact badly with TensorFlow, causing nondeterministic deadlocks. For high performance data pipelines tf.data is recommended.\n",
            "384/400 [===========================>..] - ETA: 2s - loss: 1.5858 - accuracy: 0.8208"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0t2Mnn78Px9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw9lQFM65moF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5BD-c0t5Vnc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}